# ugh, stupid wide format. This is why we can't have nice things
status_options <- data.frame(storage_resource  = c("DI", "DU", "TI", "TNU", "TBU"),
Status = c("Installed", "Used", "Installed", "Used", "Backup Used"))
st <- merge(st, status_options, all = T)
for(site in unique(st$System)){
st %>%
filter(System == site)%>%
select("storage_resource","DATE","System", "time_period","resource_value",
"TYPE","Status" )%>%
drop_na()%>%
group_by(time_period, TYPE, Status) %>%
summarise(Total = sum(resource_value), .groups= "keep") %>%
ggplot(aes(x = time_period,
y = Total,
group=Status,
colour=Status)) +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = "top",
axis.title.x=element_blank(),
plot.margin = cc_margins) +
geom_line(na.rm = TRUE, size = 1, lineend	= "round", linejoin = "round") +
scale_x_continuous(labels  = addline_format(paste(pcap_sum$Quarter, pcap_sum$Year2, sp=" ")),
breaks = pcap_sum$time_period)+
ylab("Resource [PB]") +
facet_grid(TYPE~., scale = "free_y")+
scale_color_manual(values = isedcolors)
ggsave(paste("./figures/fig_installed_storage_", utf8names[paste(site)], ".jpg", sep = ""),
width = 8, height = 4.1, path = report_path, dpi = 300, type = "cairo")
}
# read CPU, GPU, and vCPU from each tab
# job%Util, RAC%Util not used
cpu_use <-
suppressMessages(read_arc_data(root_URL, sheet_cpu)) %>%
# tag it
mutate(TYPE = "CPU") %>%
# make sure it's all factors
mutate_if(is.character,as.factor) %>%
select(-NOTES, -jobpcUtil, -RACpcUtil, -Comment)
gpu_use <-
suppressMessages(read_arc_data(root_URL, sheet_gpu)) %>%
mutate(TYPE = "GPU") %>%
mutate_if(is.character,as.factor) %>%
select(-NOTES, -jobpcUtil, -RACpcUtil, -Comment)
vcpu_use <-
suppressMessages(read_arc_data(root_URL, sheet_vcpu)) %>%
select(-Comment)
## util-tab-chart
utilization <- bind_rows(cpu_use,gpu_use,vcpu_use) %>%
mutate_if(is.character,as.factor) %>%
mutate(TP = as.yearqtr(time_period))
# filter the data
CPUGPUvCPU <- utilization %>%
filter(TP == previous_quarter) %>%
select(System, TYPE, RAC_Alloc, User, Util) %>%
arrange(TYPE,System)
# rename columns
CPUGPUvCPU <- rename(CPUGPUvCPU, Type = TYPE, System  = System, RAC = RAC_Alloc)
# plot
for(site in unique(utilization$System)){
utilization %>%
gather(Metric_type, Metric_value, User, Util, RAC_Alloc) %>%
filter(System == site)%>%
drop_na()%>%
ggplot(aes(x = time_period,
y = Metric_value,
group = Metric_type,
colour = Metric_type)) +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
axis.title.x=element_blank(),
legend.position = "top",
plot.margin = cc_margins) +
geom_line(na.rm=TRUE, size = 1, lineend	= "round", linejoin = "round") +
scale_x_continuous(labels  = addline_format(paste(pcap_sum$Quarter, pcap_sum$Year2, sp=" ")),
breaks = pcap_sum$time_period)+
ylab("Percentage") +
#ylim(0,100) +
facet_grid(TYPE~., scales = "free_y")+
scale_color_manual(values = isedcolors)
ggsave(paste("./figures/fig_util_", utf8names[paste(site)], ".jpg", sep = ""),
width = 8, height = 4.1, path = report_path, dpi = 300, type = "cairo")
}
## JOB METRICS
# now read them
job_sizes  <-
suppressMessages(read_arc_data(root_URL, sheet_size)) %>%
mutate (job_metric_type = "SIZE")
job_times  <-
suppressMessages(read_arc_data(root_URL, sheet_time)) %>%
mutate (job_metric_type = "TIME")
job_sizetimes  <-
suppressMessages(read_arc_data(root_URL, sheet_st)) %>%
mutate (job_metric_type = "SIZETIME")
job_waits  <-
suppressMessages(read_arc_data(root_URL, sheet_wait)) %>%
mutate (job_metric_type = "WAIT")
# join them
all_jobs  <-  bind_rows(job_sizes,
job_times,
job_sizetimes,
job_waits) %>%
mutate_if(is.character,as.factor) %>%
arrange(System,TYPE)
# rearrange the job metric types from alphabetial to "logical" order
all_jobs$job_metric_type = factor(all_jobs$job_metric_type,
levels = c("SIZE", "TIME", "SIZETIME", "WAIT"))
# plot the mean values of each of the metrics, per System
for(site in unique(all_jobs$System)){
all_jobs %>%
filter(System == site)%>%
ggplot(aes(x = time_period,
y = MEAN,
colour = TYPE)) +
geom_line(na.rm = TRUE, size = 1, lineend	= "round", linejoin = "round") +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = "top",
axis.title.x=element_blank(),
plot.margin = cc_margins) +
scale_x_continuous(labels  = addline_format(paste(pcap_sum$Quarter, pcap_sum$Year2, sp=" ")),
breaks = pcap_sum$time_period)+
scale_y_continuous(trans='log10') +
ylab("Mean Value") +
facet_grid(.~job_metric_type, scales = "free_y")+
scale_color_manual(values = isedcolors)
ggsave(paste("./figures/fig_alljobs_mean_stats_", utf8names[paste(site)], ".jpg", sep = ""),
width = 8, height = 4.1, path = report_path, dpi = 300, type = "cairo")
}
## JOB COUNTS
# TODO: get that ish into a loopy loop
# summarise the data
job_counts  <-  all_jobs %>%
filter(as.yearqtr(time_period) == previous_quarter,
job_metric_type == "SIZE") %>%
select(System,TYPE,N) %>%
spread(TYPE,N) %>%
adorn_totals(where = c("row"))
# rename columns
job_counts <-  rename(job_counts, System = System)
## plot time series of job counts
for(site in unique(all_jobs$System)){
all_jobs %>%
filter(System == site) %>%
filter(job_metric_type=="SIZE") %>%
ggplot(aes(x = time_period,
y = N, colour="#C4961A")) +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
axis.title.x=element_blank(),
plot.margin = cc_margins) +
geom_line(na.rm = TRUE, size = 1, lineend	= "round", linejoin = "round") +
scale_x_continuous(labels  = addline_format(paste(pcap_sum$Quarter, pcap_sum$Year2, sp=" ")),
breaks = pcap_sum$time_period)+
ylab("Metric Value") +
facet_grid(.~TYPE, scales = "free_y") +
theme(legend.position = "none")+
scale_color_manual(values = isedcolors)
ggsave(paste("./figures/fig_job_counts_", utf8names[paste(site)], ".jpg", sep = ""),
width = 8, height = 4.1, path = report_path, dpi = 300, type = "cairo")
}
## job-size-cores
# filter data
job_size  <-  all_jobs %>%
drop_na() %>%
filter(as.yearqtr(time_period) == previous_quarter,
job_metric_type == "SIZE") %>%
select(-DATE, -time_period, -job_metric_type)%>%
arrange(TYPE,System)
# rename columns
job_size <-  rename(job_size, System = System)
## job-times
job_times  <-  all_jobs %>%
drop_na() %>%
filter(as.yearqtr(time_period) == previous_quarter,
job_metric_type == "TIME") %>%
select(-DATE, -time_period, -job_metric_type)%>%
arrange(TYPE,System)
# rename columns
job_times <-  rename(job_times, System = System)
## job-size-times
# filter the data
job_size_time  <-  all_jobs %>%
drop_na() %>%
filter(as.yearqtr(time_period) == previous_quarter,
job_metric_type == "SIZETIME") %>%
select(-DATE, -time_period, -job_metric_type)%>%
arrange(TYPE,System)
# rename columns
job_size_time <-  rename(job_size_time, System = System)
## job-waits
# filter the data
job_wait <- all_jobs %>%
drop_na() %>%
filter(as.yearqtr(time_period) == previous_quarter,
job_metric_type == "WAIT") %>%
select(-DATE, -time_period, -job_metric_type)%>%
arrange(TYPE,System)
# rename columns
job_wait <-  rename(job_wait, System = System)
## TICKETS
# read the data
tv2 <-
suppressMessages(read_arc_data(root_URL, sheet_tickvol)) %>%
gather(CLOSED,Count,AN,CQ,CO,WG,CC) %>%
drop_na()
# reorder the factors for aesthetic reasons
tv2$REGION <-  factor(tv2$REGION, levels = c("AN","CO","CQ","WG","Other"))
tv2$CLOSED <-  factor(tv2$CLOSED, levels = c("AN","CO","CQ","WG","CC"))
# filter and select the data, and summarize
tickets <- tv2 %>%
filter(as.yearqtr(time_period) == previous_quarter) %>%
spread(CLOSED, Count) %>%
select(-DATE,-time_period) %>%
adorn_totals(where = c("row","col"))
# rename columns
tickets <-  rename(tickets, Region = REGION)
# all tickets for previous quarter
tickets_previous <- tv2 %>%
filter(as.yearqtr(time_period) == previous_quarter)
# bar chart
plot_tickets <- ggplot(data = tickets_previous,
aes(x = REGION,
y = Count,
fill = CLOSED)) +
geom_col(aes(fill = CLOSED),
position = "stack", width=0.5) +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
plot.margin = cc_margins) +
xlab("Customer consortium") +
ylab("Ticket count") +
theme(legend.title = element_text()) +
labs(fill = "Owning agent\nconsortium") +
scale_fill_manual(values = isedcolors)
ggsave("./figures/fig_tickets_bar.jpg",
width = 8, height = 4.1, path = report_path, dpi = 300, type = "cairo")
# bar chart - swap client region from x-axis to colour axis
plot_tickets2 <- ggplot(data = tickets_previous,
aes(x = CLOSED,
y = Count,
fill = REGION)) +
geom_col(aes(fill = REGION),
position = "stack", width=0.5) +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
plot.margin = cc_margins) +
xlab("Owning agent consortium") +
ylab("Tickets count") + #colour_cols +
theme(legend.title = element_text()) +
labs(fill = "Customer\nconsortium") +
scale_fill_manual(values = isedcolors)
generated <- tv2 %>%
group_by(time_period, REGION) %>%
summarise(generated = sum(Count), .groups="keep")
closed <- tv2 %>%
group_by(time_period, CLOSED) %>%
summarise(closed = sum(Count), .groups="keep")%>%
rename(REGION = CLOSED)
tx_compare <- merge(generated, closed)
tx_compare$ratio <- tx_compare$closed/tx_compare$generated
text_position <- aggregate(cbind(generated, ratio)~REGION,tx_compare,max)
plot_ratio <- ggplot(data=tx_compare, aes(x=generated, y=ratio,label = REGION))+
theme_light()+
theme(legend.position = "none",
plot.margin = cc_margins)+
xlab("Nb of tickets generated")+
ylab("Ratio tickets closed/tickets generated")+
geom_text(data=text_position, aes(x=generated, y=ratio, color=REGION),size=5)+
geom_path(aes(color=REGION), size= 1, arrow = arrow(type = "closed",angle = 10,length = unit(0.3, "cm")))
sef <- function(z)sd(z)/sqrt(length(z)) # function to calculate std.err
se<- aggregate(cbind(se.x=generated,se.y=ratio)~REGION,tx_compare,sef)
centroids <- aggregate(cbind(generated, ratio)~REGION,tx_compare,mean)
centroids <- merge(centroids,se, by="REGION")
info_labels<- data.frame(
x = c(0, 0, 1300, 1300),
y = c(0, 2, 0, 2),
text = c("Creates few, closes fewer", "Created few, closes more",
"Creates many, closes fewer", "Creates many, closes more")
)
plot_centroid_tickets <- ggplot(tx_compare, aes(generated,ratio))+
theme_light()+
geom_point(data=centroids, size=5,aes(color=REGION))+
geom_errorbar(data=centroids,aes(ymin=ratio-se.y,ymax=ratio+se.y, color=REGION),width=0.1)+
geom_errorbarh(data=centroids,aes(xmin=generated-se.x,xmax=generated+se.x, color=REGION),height=0.1)+
geom_abline(intercept = 1, slope = 0, color = "red")+
geom_vline(xintercept = 650, color = "red")+
geom_text(data=centroids, aes(x=generated, y=ratio, color=REGION, label = REGION),
size=5, nudge_x = 100, nudge_y= -0.1)+
xlab("Tickets Generated")+
ylab("Ratio tickets closed/tickets generated")+
theme(panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
legend.position = "none",
plot.margin = cc_margins)+
xlim(0, 1300)+ylim(0,2)+
geom_text(data = info_labels,aes(x= x, y=y, label = text), vjust = "inward", hjust = "inward")
ggsave("./figures/fig_centroids_tickets.jpg",
width = 8, height = 4.1, path = report_path, units="in", dpi = 300, type="cairo")
# Ticket closing time
# read and filter data
ticket_columns  <-  c("date", "numeric", "numeric",
"numeric","numeric","numeric", "text")
ticket_times <- read_arc_data(root_URL, sheet_ticktime) %>%
select(-P90,NOTE) %>%
gather(the_stat,the_value,MEAN, MEDIAN)
# labels and breaks
tlabels <-  as.yearqtr(ticket_times$time_period)
tbreaks <-  ticket_times$time_period
# plot timeseries of summary statistics
plot_ticket_time <- ggplot(data = ticket_times,
aes( x = time_period,
y = the_value),
group = the_stat) +
theme_light()+
theme(panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
panel.grid.minor.x = element_blank(),
panel.grid.major.x = element_blank(),
axis.title.x=element_blank(),
legend.position = "top",
plot.margin = cc_margins)+
geom_line(aes(colour=the_stat), size = 1, lineend	= "round", linejoin = "round") +
scale_x_continuous(labels  = addline_format(paste(pcap_sum$Quarter, pcap_sum$Year2, sp=" ")),
breaks = pcap_sum$time_period)+
ylab("Time to Close [days]") +
ylim(0,5) +
labs(color = "Metric")+
scale_color_manual(values = isedcolors)
# major outages
major_outages <- read_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
major_outages <- if(nrow(major_outages)== 0){
major_outages%>%
add_row(Duration ="", Status= "No outage to report", System="",Note ="")
}
# security status
security <- read_arc_data(root_URL, sheet_security)%>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, "Additional Information")
security <- if(nrow(security)== 0){
security%>%
add_row(Status= "No outage to report", System="", "Additional Information"="")
}
# incidents
incidents <- read_arc_data(root_URL, sheet_incidents)%>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, "TYPE of issue", "Brief Description of issue")
incidents <- if(nrow(incidents)== 0){
incidents%>%
add_row(System="", "TYPE of issue" ="No incident to report", "Brief Description of issue"="")
}
knitr::opts_chunk$set(echo = FALSE, fig.pos='H')
source("./RAC Expansion Report.r")
knitr::kable(pcap, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 3)),
caption = "Processing capacity (cores) for each system. The capacity is separated into CPU and GPU. Virtual CPUs (vCPUs) are specific to cloud installations and are not reported for other systems. Arbutus is cloud only.") %>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(st2, booktabs = T, format.args = list(big.mark = ","), caption = "Storage capacity at each System for disk and tape (PB). All storage figures are in base-10 units.") %>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::include_graphics("./figures/fig_processors_Arbutus.jpg")
knitr::include_graphics("./figures/fig_installed_storage_Arbutus.jpg")
knitr::include_graphics("./figures/fig_processors_Beluga.jpg")
knitr::opts_chunk$set(echo = FALSE, fig.pos='H')
source("./RAC Expansion Report.r")
knitr::kable(pcap, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 3)),
caption = "Processing capacity (cores) for each system. The capacity is separated into CPU and GPU. Virtual CPUs (vCPUs) are specific to cloud installations and are not reported for other systems. Arbutus is cloud only.") %>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(st2, booktabs = T, format.args = list(big.mark = ","), caption = "Storage capacity at each System for disk and tape (PB). All storage figures are in base-10 units.") %>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::include_graphics("./figures/fig_processors_Arbutus.jpg")
knitr::include_graphics("./figures/fig_installed_storage_Arbutus.jpg")
knitr::include_graphics("./figures/fig_processors_Beluga.jpg")
knitr::include_graphics("./figures/fig_installed_storage_Beluga.jpg")
knitr::include_graphics("./figures/fig_processors_Cedar.jpg")
knitr::include_graphics("./figures/fig_installed_storage_Cedar.jpg")
knitr::include_graphics("./figures/fig_processors_Graham.jpg")
knitr::include_graphics("./figures/fig_installed_storage_Graham.jpg")
knitr::include_graphics("./figures/fig_processors_Niagara.jpg")
knitr::include_graphics("./figures/fig_installed_storage_Niagara.jpg")
knitr::kable(top_500, booktabs = T, format.args = list(big.mark = ","),  align=c('l',rep('c', 8)), caption = "Evolution in time of each system's position in the Top 500 list.") %>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(CPUGPUvCPU, booktabs = T, format.args = list(big.mark = ","),  align=c('l',rep('c', 4)),
caption = "Percentage of ressources allocated and used.")%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::include_graphics("./figures/fig_util_Arbutus.jpg")
knitr::include_graphics("./figures/fig_util_Beluga.jpg")
knitr::include_graphics("./figures/fig_util_Cedar.jpg")
knitr::include_graphics("./figures/fig_util_Graham.jpg")
knitr::include_graphics("./figures/fig_util_Niagara.jpg")
knitr::kable(job_counts, booktabs = T, format.args = list(big.mark = ","),  align=c('l',rep('c', 3)),
caption = "Number of jobs submitted in the quarter.")%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(job_size, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 8)),
caption = "Descriptive statistics of the number of cores per job run for each system.")%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(job_times, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 8)),
caption = "Descriptive statistics of the duration, in hours, of jobs run for each system.")%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(job_size_time, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 8)),
caption = "Descriptive statistics of the product of job size in cores and the job duration, in hours, for each system.")%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(job_wait, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 8)),
caption = "Descriptive statistics of the time, in hours, spent in the queue for each system.")%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::include_graphics("./figures/fig_alljobs_mean_stats_Arbutus.jpg")
knitr::include_graphics("./figures/fig_alljobs_mean_stats_Beluga.jpg")
knitr::include_graphics("./figures/fig_alljobs_mean_stats_Cedar.jpg")
knitr::include_graphics("./figures/fig_alljobs_mean_stats_Graham.jpg")
knitr::include_graphics("./figures/fig_alljobs_mean_stats_Niagara.jpg")
plot_ticket_time
knitr::kable(tickets, booktabs = T, format.args = list(big.mark = ","), align=c('l',rep('c', 6)),
caption = "Tickets ")%>%
kableExtra::kable_styling(latex_options = "hold_position")
plot_tickets
plot_tickets2
knitr::kable(security, booktabs = T, format.args = list(big.mark = ","), caption = "Security status of security appliance deployment for each system.")%>%
kable_paper(full_width = F)%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(incidents, booktabs = T, format.args = list(big.mark = ","), caption = "Incidents.")%>%
kable_paper(full_width = F)%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(major_outages, booktabs = T, format.args = list(big.mark = ","), caption = "Major outages.")%>%
kable_paper(full_width = F)%>%
kableExtra::kable_styling(latex_options = "hold_position")
knitr::kable(major_outages, booktabs = T, format.args = list(big.mark = ","), caption = "Major outages.")%>%
kable_paper(full_width = F)%>%
kableExtra::kable_styling(latex_options = "hold_position")
major_outages
# major outages
major_outages <- read_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
major_outages <- if(nrow(major_outages)== 0){
major_outages%>%
add_row(Duration ="", Status= "No outage to report", System="",Note ="")
}
major_outages
# major outages
major_outages <- read_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
major_outages
ead_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
read_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
# major outages
major_outages <- read_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
major_outages
nrow(major_outages)
major_outages <- read_arc_data(root_URL, sheet_outages) %>%
mutate(TP = as.yearqtr(time_period))%>%
filter(TP == previous_quarter)%>%
select(System, Status, Duration, Note)
major_outages <- if(nrow(major_outages)== 0){
major_outages%>%
add_row(Duration ="", Status= "No outage to report", System="",Note ="")
} else {major_outages <- major_outages}
knitr::kable(major_outages, booktabs = T, format.args = list(big.mark = ","), caption = "Major outages.")%>%
kable_paper(full_width = F)%>%
kableExtra::kable_styling(latex_options = "hold_position")
install.packages("tabulizer")
library(tabulizer)
install.packages("tabulizerjars")
install.packages("tabulizerjars")
library(tabulizerjars)
shiny::runApp('C:/Users/steak/OneDrive - Université Laval/Gitlab/racdashboard')
runApp('C:/Users/steak/OneDrive - Université Laval/Gitlab/racdashboard')
runApp('C:/Users/steak/OneDrive - Université Laval/Gitlab/racdashboard')
runApp('C:/Users/steak/OneDrive - Université Laval/Gitlab/racdashboard')
runApp('C:/Users/steak/OneDrive - Université Laval/Gitlab/racdashboard')
shiny::runApp('C:/Users/steak/OneDrive - Université Laval/Gitlab/racdashboard')
update.packages()
install.packages("vscDebugger")
setwd("c://Users/steak/OneDrive - Université Laval/GitHub/paraview_national/data/")
data_lake <- read.csv("./lac_full_volume.csv", header =T)
names(data_lake)
lk <- daa_lake %>% rename(bathy=elevation2)
library(dplyr)
lk <- daa_lake %>% rename(bathy=elevation2)
lk <- data_lake %>% rename(bathy=elevation2)
names(lk)
write.csv(lk, "./lac_volume.csv", rownames = F )
write.csv(lk, "./lac_volume.csv", rowname = F )
write.csv(lk, "./lac_volume.csv", row.names = F )
